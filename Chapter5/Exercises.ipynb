{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "What is the fundamental idea behind Support Vector Machines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines try to find the best line that separates the classes we are classifying (by trying to get the line with the highest distance to each class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "What is a support vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A support vector is an instance of a class that is determining the decision boundary of the support vector machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Why is it important to scale the inputs when using SVMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary made by the SVM is affected by features scales. If we have very different scales along each feature we will get a poor decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Can an SVM classifier output a confidence score when it classifies an instance? What about a probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM can output the distance between the instance and the decision boundary, which can be used as a confidence score of the classification. However, support vector machines can't output a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Should you use the primal or the dual form of the SVM problem to train a model on a training set with millions of instances and hundreds of features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primal form should be used in this case, as its complexity is linear in regards to the number of features m, while the complexity of the dual form ranges from m^2 to m^3. Dual form allows us to do the kernel trick, and is much faster when the number of instances is smaller than the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "Say you trained an SVM classifier with an RBF kernel. It seems to underfit the training set: should you increase or decrease gamma? What about C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the classifier is suffering from high bias (underfitting) the best solution would be to decrease regularization, which means we should increase both gamma and C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "How should you set the QP parameters (H, f, A, and b) to solve the soft margin linear SVM classifier problem using an off-the-shelf QP solver?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "Train a LinearSVC on a linearly separable dataset. Then train an SVC and a SGDClassifier on the same dataset. See if you can get them to produce roughly the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]\n",
    "\n",
    "setosa_or_versicolor = (y == 0) | (y == 1)\n",
    "X = X[setosa_or_versicolor]\n",
    "y = y[setosa_or_versicolor]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 4\n",
    "alpha = 1 / (C * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LinearSVC - Intercept: [0.28480924] - Coefs: [[1.05542607 1.09851927]]\n",
      "Classifier: SVC - Intercept: [0.31933577] - Coefs: [[1.1223101  1.02531081]]\n",
      "Classifier: SGDClassifier - Intercept: [0.3210888] - Coefs: [[1.12603939 1.02562733]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classifiers = [\n",
    "    LinearSVC(loss=\"hinge\", C=C),\n",
    "    SVC(kernel=\"linear\", C=C),\n",
    "    SGDClassifier(max_iter=1000, alpha=alpha)\n",
    "]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X, y)\n",
    "    print(\"Classifier: {0} - Intercept: {1} - Coefs: {2}\".format(\n",
    "            clf.__class__.__name__, clf.intercept_, clf.coef_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
